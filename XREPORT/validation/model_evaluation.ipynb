{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# set warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# import modules and classes\n",
    "from XREPORT.commons.utils.dataloader.generators import build_tensor_dataset\n",
    "from XREPORT.commons.utils.models.inferencer import TextGenerator\n",
    "from XREPORT.commons.constants import CONFIG, DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected and load the pretrained model, then print the summary \n",
    "modelserializer = ModelSerializer()         \n",
    "model, parameters = modelserializer.load_pretrained_model()\n",
    "model_folder = modelserializer.loaded_model_folder\n",
    "model.summary(expand_nested=True)\n",
    "\n",
    "# Load pretrained model and its parameters\n",
    "generator = TextGenerator(cnf.seed) \n",
    "model, parameters = inference.load_pretrained_model(CHECKPOINT_PATH)\n",
    "\n",
    "\n",
    "   \n",
    "dataserializer = DataSerializer()   \n",
    "modelserializer = ModelSerializer()     \n",
    "\n",
    "# select a fraction of data for training\n",
    "images_paths = get_images_path(ENCODED_INPUT_PATH)\n",
    "\n",
    "# selected and load the pretrained model, then print the summary     \n",
    "print('\\nLoading specific checkpoint from pretrained models\\n')   \n",
    "model, parameters = modelserializer.load_pretrained_model()\n",
    "model.summary(expand_nested=True)\n",
    "\n",
    "# define preprocessed data path\n",
    "preprocessing_path = os.path.join(model_path, 'preprocessing')\n",
    "\n",
    "# load preprocessed csv files (train and test datasets)\n",
    "file_loc = os.path.join(preprocessing_path, 'XREP_train.csv') \n",
    "train_data = pd.read_csv(file_loc, encoding = 'utf-8', sep=';', low_memory=False)\n",
    "file_loc = os.path.join(preprocessing_path, 'XREP_test.csv') \n",
    "test_data = pd.read_csv(file_loc, encoding = 'utf-8', sep=';', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create generator and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize training device\n",
    "trainer = ModelTraining(device=cnf.ML_DEVICE, seed=cnf.seed)\n",
    "\n",
    "# initialize the images generator for the train and test data, and create the \n",
    "# tf.dataset according to batch shapes\n",
    "train_generator = DataGenerator(train_data, cnf.BATCH_SIZE, cnf.IMG_SHAPE, \n",
    "                                shuffle=True, augmentation=cnf.IMG_AUGMENT)\n",
    "test_generator = DataGenerator(test_data, cnf.BATCH_SIZE, cnf.IMG_SHAPE, \n",
    "                               shuffle=True, augmentation=cnf.IMG_AUGMENT)\n",
    "\n",
    "# initialize the TensorDataSet class with the generator instances\n",
    "# create the tf.datasets using the previously initialized generators \n",
    "datamaker = TensorDataSet()\n",
    "train_dataset = datamaker.create_tf_dataset(train_generator)\n",
    "test_dataset = datamaker.create_tf_dataset(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_samples = train_data.shape[0]\n",
    "num_test_samples = test_data.shape[0]\n",
    "\n",
    "print(f'''\n",
    "-------------------------------------------------------------------------------\n",
    "XRAYREP evaluation report\n",
    "-------------------------------------------------------------------------------\n",
    "Number of train samples: {num_train_samples}\n",
    "Number of test samples:  {num_test_samples}\n",
    "-------------------------------------------------------------------------------\n",
    "Batch size:              {cnf.BATCH_SIZE}\n",
    "Epochs:                  {cnf.EPOCHS}\n",
    "-------------------------------------------------------------------------------\n",
    "''')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Aquarius",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
